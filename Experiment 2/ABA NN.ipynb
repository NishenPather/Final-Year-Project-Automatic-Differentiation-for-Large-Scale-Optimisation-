{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ABALONE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('abalone.data',\n",
    "         names=['sex','length','diameter','height','wholeWeight','shuckedWeight','visceraWeight','shellWeight','rings'],delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data['sex'].to_numpy()\n",
    "x2 = data['length'].to_numpy(np.float64)\n",
    "x3 = data['diameter'].to_numpy(np.float64)\n",
    "x4 = data['height'].to_numpy(np.float64)\n",
    "x5 = data['wholeWeight'].to_numpy(np.float64)\n",
    "x6 = data['shuckedWeight'].to_numpy(np.float64)\n",
    "x7 = data['visceraWeight'].to_numpy(np.float64)\n",
    "x8 = data['shellWeight'].to_numpy(np.float64)\n",
    "y = data['rings'].to_numpy(np.float64)\n",
    "\n",
    "#getting x1 code\n",
    "x1_code = np.empty(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'M' 'F' 'M' 'I' 'I' 'F' 'F' 'M']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "x1_OH = enc.fit_transform(x1.reshape(-1, 1))\n",
    "print(x1[0:9])\n",
    "x1_OH.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.    , 1.    , ..., 0.2245, 0.101 , 0.15  ],\n",
       "       [0.    , 0.    , 1.    , ..., 0.0995, 0.0485, 0.07  ],\n",
       "       [1.    , 0.    , 0.    , ..., 0.2565, 0.1415, 0.21  ],\n",
       "       ...,\n",
       "       [0.    , 0.    , 1.    , ..., 0.5255, 0.2875, 0.308 ],\n",
       "       [1.    , 0.    , 0.    , ..., 0.531 , 0.261 , 0.296 ],\n",
       "       [0.    , 0.    , 1.    , ..., 0.9455, 0.3765, 0.495 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataArr = np.empty([0,10])\n",
    "\n",
    "for i in range(len(x2)):\n",
    "    x1_temp = np.empty([0,3])\n",
    "    x1_temp = np.append(x1_temp,x1_OH.toarray()[i])\n",
    "    row = np.array([x1_temp[0],x1_temp[1],x1_temp[2],x2[i],x3[i],x4[i],x5[i],x6[i],x7[i],x8[i]])\n",
    "    dataArr = np.append(dataArr,np.array([row]),axis=0)\n",
    "dataArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale output data\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "y_shape = y.shape\n",
    "y = scaler.fit_transform(y.reshape(-1, 1))\n",
    "y = y.reshape(y_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataArr, y, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaled output network\n",
    "inputs = 10\n",
    "firstLayer = 60\n",
    "output = 1\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(inputs, firstLayer),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(firstLayer, output),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "# loss_func = torch.nn.MSELoss(reduction='mean')  # this is for regression mean squared loss ---> can change to sum. Is mean currently\n",
    "loss_func = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "BATCH_SIZE = 1399#len(x_train)#700 \n",
    "EPOCH = 1500\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x_train, y_train)\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, num_workers=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pytorch Grad Descent\n",
    "# loss_graph = torch.empty(0)\n",
    "# start_time = time.perf_counter()\n",
    "# for epoch in range(EPOCH):\n",
    "#     for step, (batch_x, batch_y) in enumerate(loader): # for each training step\n",
    "        \n",
    "#         b_x = Variable(batch_x,requires_grad=False)\n",
    "#         b_y = Variable(batch_y)\n",
    "\n",
    "#         y_pred = net(b_x.float())     # input x and predict based on x\n",
    "        \n",
    "# #         loss =  loss_func(y_pred, b_y)     # must be (1. nn output, 2. target)\n",
    "# #         loss_graph = torch.cat((loss_graph, loss.detach().flatten()),0)\n",
    "        \n",
    "#         ##Scaled Output Change\n",
    "#         loss1 =  loss_func(torch.from_numpy(scaler.inverse_transform(y_pred.detach().numpy())), torch.from_numpy(scaler.inverse_transform(b_y.detach().numpy()))) \n",
    "#         loss =  loss_func(y_pred, b_y) \n",
    "#         loss_graph = torch.cat((loss_graph, loss.detach().flatten()),0) \n",
    "#         print(\"error at epoch \",epoch,\"is \",loss)\n",
    "\n",
    "# #         print(\"epoch: \",epoch,\" loss: \",loss.detach().numpy())\n",
    "#         optimizer.zero_grad()   # clear gradients for next train\n",
    "#         loss.backward()         # backpropagation, compute gradients\n",
    "#         optimizer.step()        # apply gradients\n",
    "    \n",
    "#     if ((loss_graph[2*epoch+1]+loss_graph[2*epoch])/2 <0.006):\n",
    "#         break\n",
    "        \n",
    "# print(\"time taken to execute: \",time.perf_counter()-start_time) \n",
    "# plt.plot(loss_graph.numpy()) \n",
    "# pickle.dump(loss_graph, open( \"RSS_GD.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error at epoch  0 is  tensor(0.1966)\n",
      "error at epoch  0 is  tensor(0.0080)\n",
      "error at epoch  1 is  tensor(0.0088)\n",
      "error at epoch  1 is  tensor(0.0064)\n",
      "error at epoch  2 is  tensor(0.0061)\n",
      "error at epoch  2 is  tensor(0.0102)\n",
      "error at epoch  3 is  tensor(0.0052)\n",
      "error at epoch  3 is  tensor(0.0077)\n",
      "error at epoch  4 is  tensor(0.0053)\n",
      "error at epoch  4 is  tensor(0.0081)\n",
      "error at epoch  5 is  tensor(0.0054)\n",
      "error at epoch  5 is  tensor(0.0064)\n",
      "time taken to execute:  114.92419150000023\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_graph = torch.empty(0)\n",
    "u=0.1 #beta multiply identity matrix\n",
    "b = 10\n",
    "V_prev = 0 #intialise performance index\n",
    "start_time = time.perf_counter()\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (batch_x, batch_y) in enumerate(loader): # for each training step\n",
    "        \n",
    "        b_x = Variable(batch_x,requires_grad=False)\n",
    "        b_y = batch_y.float()\n",
    "        y_pred = net(b_x)     # predict outputs based on x\n",
    "        num_param = inputs*firstLayer+firstLayer+firstLayer*output+output\n",
    "        \n",
    "        jacobian = torch.empty(len(batch_y), num_param) # errors by weights\n",
    "\n",
    "        for n in range(len(batch_y)): #batch length is num of rows\n",
    "            net.zero_grad()\n",
    "            e = b_y[n]-y_pred[n]\n",
    "            e.backward(retain_graph=True)\n",
    "            with torch.no_grad():\n",
    "                param_grads = torch.empty(0) \n",
    "\n",
    "                for param in net.parameters():\n",
    "                    param_grads = torch.cat((param_grads, torch.flatten(param.grad).detach()),0) #puts gradient of params w.r.t e\n",
    "\n",
    "                for m in range(num_param): #num params is num of coloumns\n",
    "                    jacobian[n][m] = param_grads[m]\n",
    "        with torch.no_grad():\n",
    "            #determine dParam  \n",
    "            V_current = 0.5*torch.sum(torch.square(b_y-y_pred)) #performance index\n",
    "            if(V_current > V_prev):\n",
    "                u *= b\n",
    "            else:\n",
    "                u /= b\n",
    "            V_prev = V_current\n",
    "#             print(\"V: \",V_current, \"u is: \",u)\n",
    "            dParam = torch.matmul(torch.matmul(torch.inverse(torch.matmul(torch.transpose(jacobian,-1,0),jacobian) + u*torch.eye(num_param, num_param)),torch.transpose(jacobian,-1,0)),b_y-y_pred)\n",
    "            \n",
    "\n",
    "            loss =  loss_func(y_pred, b_y) \n",
    "            loss_graph = torch.cat((loss_graph, loss.detach().flatten()),0) \n",
    "            print(\"error at epoch \",epoch,\"is \",loss)\n",
    "\n",
    "            #update the params\n",
    "            c = 0\n",
    "        with torch.no_grad():    \n",
    "            for param in net.parameters():\n",
    "                s = param.shape\n",
    "                dParamUpdate = dParam[c:c+len(param.flatten())]\n",
    "                c+= len(dParamUpdate)\n",
    "                param -= 1*dParamUpdate.reshape(s)\n",
    "\n",
    "            \n",
    "    \n",
    "    if ((loss_graph[2*epoch+1]+loss_graph[2*epoch])/2 <0.006):\n",
    "        break\n",
    "    \n",
    "print(\"time taken to execute: \",time.perf_counter()-start_time)     \n",
    "plt.plot(loss_graph.numpy())  \n",
    "pickle.dump(loss_graph, open( \"RSS_LM.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "y_pred = net(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.numpy()\n",
    "y_pred = y_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error  1 is  0.1103383 correct was [0.2857143] predicted was  [0.3960526]\n",
      "Error  2 is  0.06795347 correct was [0.25] predicted was  [0.31795347]\n",
      "Error  3 is  0.10062501 correct was [0.2857143] predicted was  [0.3863393]\n",
      "Error  4 is  0.052281946 correct was [0.4642857] predicted was  [0.41200376]\n",
      "Error  5 is  0.09361996 correct was [0.21428572] predicted was  [0.30790567]\n",
      "Error  6 is  0.11977413 correct was [0.17857143] predicted was  [0.29834557]\n",
      "Error  7 is  0.32486343 correct was [0.75] predicted was  [0.42513657]\n",
      "Error  8 is  0.056781456 correct was [0.2857143] predicted was  [0.22893284]\n",
      "Error  9 is  0.028673887 correct was [0.25] predicted was  [0.2786739]\n",
      "Error  10 is  0.14431995 correct was [0.60714287] predicted was  [0.4628229]\n",
      "Error  11 is  0.061576188 correct was [0.35714287] predicted was  [0.41871905]\n",
      "Error  12 is  0.05655083 correct was [0.4642857] predicted was  [0.40773487]\n",
      "Error  13 is  0.12569708 correct was [0.6785714] predicted was  [0.5528743]\n",
      "Error  14 is  0.1450214 correct was [0.39285713] predicted was  [0.24783574]\n",
      "Error  15 is  0.0273453 correct was [0.21428572] predicted was  [0.24163102]\n",
      "Error  16 is  0.03866476 correct was [0.35714287] predicted was  [0.3184781]\n",
      "Error  17 is  0.05500087 correct was [0.32142857] predicted was  [0.37642944]\n",
      "Error  18 is  0.118774265 correct was [0.2857143] predicted was  [0.40448856]\n",
      "Error  19 is  0.044132322 correct was [0.32142857] predicted was  [0.3655609]\n",
      "Error  20 is  0.036541 correct was [0.17857143] predicted was  [0.21511243]\n",
      "Error  21 is  0.03734705 correct was [0.32142857] predicted was  [0.35877562]\n",
      "Error  22 is  0.027836561 correct was [0.25] predicted was  [0.27783656]\n",
      "Error  23 is  0.04181674 correct was [0.14285715] predicted was  [0.18467389]\n",
      "Error  24 is  0.08646682 correct was [0.17857143] predicted was  [0.26503825]\n",
      "Error  25 is  0.036633983 correct was [0.17857143] predicted was  [0.21520542]\n",
      "Error  26 is  0.13117355 correct was [0.39285713] predicted was  [0.5240307]\n",
      "Error  27 is  0.20087773 correct was [0.60714287] predicted was  [0.40626514]\n",
      "Error  28 is  0.042325735 correct was [0.25] predicted was  [0.29232574]\n",
      "Error  29 is  0.04592392 correct was [0.42857143] predicted was  [0.3826475]\n",
      "Error  30 is  0.05973044 correct was [0.32142857] predicted was  [0.26169813]\n",
      "Error  31 is  0.13363904 correct was [0.60714287] predicted was  [0.47350383]\n",
      "Error  32 is  0.037114315 correct was [0.10714286] predicted was  [0.14425717]\n",
      "Error  33 is  0.048047066 correct was [0.25] predicted was  [0.29804707]\n",
      "Error  34 is  0.027974695 correct was [0.14285715] predicted was  [0.11488245]\n",
      "Error  35 is  0.022266388 correct was [0.21428572] predicted was  [0.19201933]\n",
      "Error  36 is  0.04574105 correct was [0.32142857] predicted was  [0.36716962]\n",
      "Error  37 is  0.13113368 correct was [0.5] predicted was  [0.36886632]\n",
      "Error  38 is  0.26340652 correct was [0.71428573] predicted was  [0.45087922]\n",
      "Error  39 is  0.07814607 correct was [0.32142857] predicted was  [0.39957464]\n",
      "Error  40 is  0.02573955 correct was [0.21428572] predicted was  [0.24002527]\n",
      "Error  41 is  0.059264824 correct was [0.2857143] predicted was  [0.22644947]\n",
      "Error  42 is  0.025430493 correct was [0.10714286] predicted was  [0.13257335]\n",
      "Error  43 is  0.06393936 correct was [0.14285715] predicted was  [0.20679651]\n",
      "Error  44 is  0.06743468 correct was [0.21428572] predicted was  [0.2817204]\n",
      "Error  45 is  0.13891563 correct was [0.2857143] predicted was  [0.42462993]\n",
      "Error  46 is  0.041383713 correct was [0.32142857] predicted was  [0.36281228]\n",
      "Error  47 is  0.047933593 correct was [0.21428572] predicted was  [0.2622193]\n",
      "Error  48 is  0.26079524 correct was [0.78571427] predicted was  [0.52491903]\n",
      "Error  49 is  0.124523014 correct was [0.4642857] predicted was  [0.3397627]\n",
      "Error  50 is  0.12967253 correct was [0.5] predicted was  [0.37032747]\n",
      "Error  51 is  0.08087325 correct was [0.5] predicted was  [0.41912675]\n",
      "Error  52 is  0.04689595 correct was [0.32142857] predicted was  [0.36832452]\n",
      "Error  53 is  0.101460725 correct was [0.17857143] predicted was  [0.28003216]\n",
      "Error  54 is  0.25822407 correct was [0.64285713] predicted was  [0.38463306]\n",
      "Error  55 is  0.111022204 correct was [0.32142857] predicted was  [0.43245077]\n",
      "Error  56 is  0.08098206 correct was [0.32142857] predicted was  [0.40241063]\n",
      "Error  57 is  0.118234485 correct was [0.2857143] predicted was  [0.40394878]\n",
      "Error  58 is  0.04284209 correct was [0.35714287] predicted was  [0.39998496]\n",
      "Error  59 is  0.068559855 correct was [0.32142857] predicted was  [0.38998842]\n",
      "Error  60 is  0.0347984 correct was [0.17857143] predicted was  [0.21336983]\n",
      "Error  61 is  0.15228939 correct was [0.5] predicted was  [0.3477106]\n",
      "Error  62 is  0.11365284 correct was [0.21428572] predicted was  [0.32793856]\n",
      "Error  63 is  0.022436142 correct was [0.21428572] predicted was  [0.19184957]\n",
      "Error  64 is  0.054290086 correct was [0.42857143] predicted was  [0.48286152]\n",
      "Error  65 is  0.111750975 correct was [0.21428572] predicted was  [0.3260367]\n",
      "Error  66 is  0.075163096 correct was [0.2857143] predicted was  [0.3608774]\n",
      "Error  67 is  0.057211846 correct was [0.32142857] predicted was  [0.3786404]\n",
      "Error  68 is  0.04898095 correct was [0.25] predicted was  [0.29898095]\n",
      "Error  69 is  0.09259996 correct was [0.4642857] predicted was  [0.37168574]\n",
      "Error  70 is  0.10903233 correct was [0.60714287] predicted was  [0.49811053]\n",
      "Error  71 is  0.04327309 correct was [0.25] predicted was  [0.2932731]\n",
      "Error  72 is  0.038094968 correct was [0.2857143] predicted was  [0.32380927]\n",
      "Error  73 is  0.08408469 correct was [0.39285713] predicted was  [0.30877244]\n",
      "Error  74 is  0.06793982 correct was [0.35714287] predicted was  [0.42508268]\n",
      "Error  75 is  0.046765536 correct was [0.32142857] predicted was  [0.3681941]\n",
      "Error  76 is  0.066310406 correct was [0.25] predicted was  [0.3163104]\n",
      "Error  77 is  0.05979225 correct was [0.4642857] predicted was  [0.40449345]\n",
      "Error  78 is  0.0862616 correct was [0.2857143] predicted was  [0.3719759]\n",
      "Error  79 is  0.22922057 correct was [0.6785714] predicted was  [0.44935083]\n",
      "Error  80 is  0.03954062 correct was [0.2857143] predicted was  [0.32525492]\n",
      "Error  81 is  0.063681334 correct was [0.2857143] predicted was  [0.34939563]\n",
      "Error  82 is  0.1582838 correct was [0.32142857] predicted was  [0.47971237]\n",
      "Error  83 is  0.030627102 correct was [0.2857143] predicted was  [0.3163414]\n",
      "Error  84 is  0.07491697 correct was [0.25] predicted was  [0.17508303]\n",
      "Error  85 is  0.08883354 correct was [0.32142857] predicted was  [0.4102621]\n",
      "Error  86 is  0.06409684 correct was [0.14285715] predicted was  [0.20695399]\n",
      "Error  87 is  0.05241108 correct was [0.25] predicted was  [0.30241108]\n",
      "Error  88 is  0.08787979 correct was [0.21428572] predicted was  [0.3021655]\n",
      "Error  89 is  0.06261361 correct was [0.25] predicted was  [0.3126136]\n",
      "Error  90 is  0.054536074 correct was [0.32142857] predicted was  [0.37596464]\n",
      "Error  91 is  0.067233205 correct was [0.5] predicted was  [0.4327668]\n",
      "Error  92 is  0.05221793 correct was [0.32142857] predicted was  [0.3736465]\n",
      "Error  93 is  0.07776925 correct was [0.32142857] predicted was  [0.39919782]\n",
      "Error  94 is  0.16362882 correct was [0.25] predicted was  [0.41362882]\n",
      "Error  95 is  0.047883093 correct was [0.35714287] predicted was  [0.30925977]\n",
      "Error  96 is  0.037715197 correct was [0.25] predicted was  [0.2877152]\n",
      "Error  97 is  0.0706808 correct was [0.39285713] predicted was  [0.46353793]\n",
      "Error  98 is  0.025078535 correct was [0.25] predicted was  [0.27507854]\n",
      "Error  99 is  0.04565884 correct was [0.17857143] predicted was  [0.22423027]\n",
      "Error  100 is  0.06468639 correct was [0.2857143] predicted was  [0.3504007]\n",
      "Error  101 is  0.07318419 correct was [0.39285713] predicted was  [0.46604133]\n",
      "Error  102 is  0.05134484 correct was [0.32142857] predicted was  [0.3727734]\n",
      "Error  103 is  0.0760625 correct was [0.5714286] predicted was  [0.4953661]\n",
      "Error  104 is  0.11207461 correct was [0.25] predicted was  [0.3620746]\n",
      "Error  105 is  0.080541134 correct was [0.25] predicted was  [0.33054113]\n",
      "Error  106 is  0.048199624 correct was [0.32142857] predicted was  [0.3696282]\n",
      "Error  107 is  0.058165282 correct was [0.2857143] predicted was  [0.34387958]\n",
      "Error  108 is  0.065552115 correct was [0.25] predicted was  [0.31555212]\n",
      "Error  109 is  0.09972371 correct was [0.21428572] predicted was  [0.31400943]\n",
      "Error  110 is  0.07664622 correct was [0.21428572] predicted was  [0.29093194]\n",
      "Error  111 is  0.03439331 correct was [0.25] predicted was  [0.2843933]\n",
      "Error  112 is  0.09542307 correct was [0.32142857] predicted was  [0.41685164]\n",
      "Error  113 is  0.053200096 correct was [0.2857143] predicted was  [0.3389144]\n",
      "Error  114 is  0.11416936 correct was [0.25] predicted was  [0.36416936]\n",
      "Error  115 is  0.06602335 correct was [0.53571427] predicted was  [0.46969092]\n",
      "Error  116 is  0.051611155 correct was [0.42857143] predicted was  [0.37696028]\n",
      "Error  117 is  0.2206307 correct was [0.5714286] predicted was  [0.3507979]\n",
      "Error  118 is  0.109247655 correct was [0.32142857] predicted was  [0.43067622]\n",
      "Error  119 is  0.06576806 correct was [0.35714287] predicted was  [0.42291093]\n",
      "Error  120 is  0.07285187 correct was [0.2857143] predicted was  [0.35856616]\n",
      "Error  121 is  0.16404575 correct was [0.5714286] predicted was  [0.40738285]\n",
      "Error  122 is  0.11467177 correct was [0.35714287] predicted was  [0.47181463]\n",
      "Error  123 is  0.03805463 correct was [0.2857143] predicted was  [0.24765967]\n",
      "Error  124 is  0.02743566 correct was [0.25] predicted was  [0.27743566]\n",
      "Error  125 is  0.04705289 correct was [0.14285715] predicted was  [0.18991004]\n",
      "Error  126 is  0.04617986 correct was [0.2857143] predicted was  [0.33189416]\n",
      "Error  127 is  0.11288786 correct was [0.25] predicted was  [0.36288786]\n",
      "Error  128 is  0.04644543 correct was [0.35714287] predicted was  [0.4035883]\n",
      "Error  129 is  0.061383456 correct was [0.2857143] predicted was  [0.34709775]\n",
      "Error  130 is  0.08931488 correct was [0.39285713] predicted was  [0.482172]\n",
      "Error  131 is  0.06491622 correct was [0.2857143] predicted was  [0.35063052]\n",
      "Error  132 is  0.04402131 correct was [0.39285713] predicted was  [0.43687844]\n",
      "Error  133 is  0.040906996 correct was [0.2857143] predicted was  [0.3266213]\n",
      "Error  134 is  0.034865156 correct was [0.25] predicted was  [0.21513484]\n",
      "Error  135 is  0.05013396 correct was [0.21428572] predicted was  [0.26441967]\n",
      "Error  136 is  0.02889368 correct was [0.2857143] predicted was  [0.31460798]\n",
      "Error  137 is  0.0657216 correct was [0.32142857] predicted was  [0.38715017]\n",
      "Error  138 is  0.12129682 correct was [0.39285713] predicted was  [0.51415396]\n",
      "Error  139 is  0.030208468 correct was [0.21428572] predicted was  [0.24449418]\n",
      "Error  140 is  0.06701681 correct was [0.32142857] predicted was  [0.38844538]\n",
      "Error  141 is  0.04412307 correct was [0.21428572] predicted was  [0.25840878]\n",
      "Error  142 is  0.05386298 correct was [0.10714286] predicted was  [0.16100584]\n",
      "Error  143 is  0.10684943 correct was [0.25] predicted was  [0.35684943]\n",
      "Error  144 is  0.15053302 correct was [0.35714287] predicted was  [0.5076759]\n",
      "Error  145 is  0.031070262 correct was [0.2857143] predicted was  [0.25464404]\n",
      "Error  146 is  0.038211703 correct was [0.25] predicted was  [0.2882117]\n",
      "Error  147 is  0.05961737 correct was [0.2857143] predicted was  [0.34533167]\n",
      "Error  148 is  0.042801514 correct was [0.21428572] predicted was  [0.25708723]\n",
      "Error  149 is  0.082587734 correct was [0.21428572] predicted was  [0.29687345]\n",
      "Error  150 is  0.070463076 correct was [0.17857143] predicted was  [0.24903451]\n",
      "Error  151 is  0.025428295 correct was [0.21428572] predicted was  [0.23971401]\n",
      "Error  152 is  0.07344112 correct was [0.2857143] predicted was  [0.35915542]\n",
      "Error  153 is  0.0995737 correct was [0.2857143] predicted was  [0.385288]\n",
      "Error  154 is  0.09477663 correct was [0.5] predicted was  [0.40522337]\n",
      "Error  155 is  0.056771338 correct was [0.35714287] predicted was  [0.4139142]\n",
      "Error  156 is  0.039880842 correct was [0.2857143] predicted was  [0.32559514]\n",
      "Error  157 is  0.05845982 correct was [0.39285713] predicted was  [0.45131695]\n",
      "Error  158 is  0.08736929 correct was [0.4642857] predicted was  [0.3769164]\n",
      "Error  159 is  0.22557074 correct was [0.64285713] predicted was  [0.4172864]\n",
      "Error  160 is  0.20172608 correct was [0.53571427] predicted was  [0.3339882]\n",
      "Error  161 is  0.073900476 correct was [0.21428572] predicted was  [0.2881862]\n",
      "Error  162 is  0.050747275 correct was [0.21428572] predicted was  [0.16353844]\n",
      "Error  163 is  0.0717791 correct was [0.4642857] predicted was  [0.3925066]\n",
      "Error  164 is  0.059001267 correct was [0.39285713] predicted was  [0.33385587]\n",
      "Error  165 is  0.061175004 correct was [0.17857143] predicted was  [0.23974644]\n",
      "Error  166 is  0.065332174 correct was [0.25] predicted was  [0.31533217]\n",
      "Error  167 is  0.05066611 correct was [0.17857143] predicted was  [0.22923754]\n",
      "Error  168 is  0.06459224 correct was [0.25] predicted was  [0.31459224]\n",
      "Error  169 is  0.23612922 correct was [0.60714287] predicted was  [0.37101364]\n",
      "Error  170 is  0.055446833 correct was [0.32142857] predicted was  [0.3768754]\n",
      "Error  171 is  0.059599757 correct was [0.53571427] predicted was  [0.4761145]\n",
      "Error  172 is  0.07833752 correct was [0.2857143] predicted was  [0.36405182]\n",
      "Error  173 is  0.025831446 correct was [0.17857143] predicted was  [0.15273999]\n",
      "Error  174 is  0.03177157 correct was [0.2857143] predicted was  [0.25394273]\n",
      "Error  175 is  0.06868455 correct was [0.42857143] predicted was  [0.35988688]\n",
      "Error  176 is  0.033196837 correct was [0.14285715] predicted was  [0.17605399]\n",
      "Error  177 is  0.15487823 correct was [0.2857143] predicted was  [0.44059253]\n",
      "Error  178 is  0.05708453 correct was [0.32142857] predicted was  [0.3785131]\n",
      "Error  179 is  0.028744668 correct was [0.14285715] predicted was  [0.11411248]\n",
      "Error  180 is  0.033702582 correct was [0.32142857] predicted was  [0.35513115]\n",
      "Error  181 is  0.09520933 correct was [0.32142857] predicted was  [0.4166379]\n",
      "Error  182 is  0.012362532 correct was [0.10714286] predicted was  [0.11950539]\n",
      "Error  183 is  0.06937373 correct was [0.5] predicted was  [0.43062627]\n",
      "Error  184 is  0.040664718 correct was [0.2857143] predicted was  [0.24504958]\n",
      "Error  185 is  0.07716155 correct was [0.5] predicted was  [0.42283845]\n",
      "Error  186 is  0.09355509 correct was [0.25] predicted was  [0.3435551]\n",
      "Error  187 is  0.07504007 correct was [0.32142857] predicted was  [0.39646864]\n",
      "Error  188 is  0.03519258 correct was [0.2857143] predicted was  [0.32090688]\n",
      "Error  189 is  0.14218217 correct was [0.60714287] predicted was  [0.4649607]\n",
      "Error  190 is  0.07899833 correct was [0.25] predicted was  [0.32899833]\n",
      "Error  191 is  0.02213338 correct was [0.14285715] predicted was  [0.16499053]\n",
      "Error  192 is  0.041622877 correct was [0.25] predicted was  [0.29162288]\n",
      "Error  193 is  0.022671 correct was [0.17857143] predicted was  [0.20124243]\n",
      "Error  194 is  0.097815126 correct was [0.4642857] predicted was  [0.36647058]\n",
      "Error  195 is  0.049152434 correct was [0.39285713] predicted was  [0.3437047]\n",
      "Error  196 is  0.03765455 correct was [0.32142857] predicted was  [0.28377402]\n",
      "Error  197 is  0.030670136 correct was [0.14285715] predicted was  [0.11218701]\n",
      "Error  198 is  0.25313485 correct was [0.78571427] predicted was  [0.5325794]\n",
      "Error  199 is  0.05638179 correct was [0.2857143] predicted was  [0.3420961]\n",
      "Error  200 is  0.030982614 correct was [0.21428572] predicted was  [0.24526833]\n",
      "Error  201 is  0.069262505 correct was [0.25] predicted was  [0.3192625]\n",
      "Error  202 is  0.07730135 correct was [0.42857143] predicted was  [0.35127008]\n",
      "Error  203 is  0.06938559 correct was [0.5714286] predicted was  [0.502043]\n",
      "Error  204 is  0.11902501 correct was [0.21428572] predicted was  [0.33331072]\n",
      "Error  205 is  0.06608558 correct was [0.25] predicted was  [0.31608558]\n",
      "Error  206 is  0.07076013 correct was [0.25] predicted was  [0.32076013]\n",
      "Error  207 is  0.22706904 correct was [0.21428572] predicted was  [0.44135475]\n",
      "Error  208 is  0.026507258 correct was [0.21428572] predicted was  [0.24079297]\n",
      "Error  209 is  0.05386877 correct was [0.25] predicted was  [0.30386877]\n",
      "Error  210 is  0.04118654 correct was [0.32142857] predicted was  [0.3626151]\n",
      "Error  211 is  0.10855672 correct was [0.32142857] predicted was  [0.42998528]\n",
      "Error  212 is  0.040212482 correct was [0.2857143] predicted was  [0.32592678]\n",
      "Error  213 is  0.047148228 correct was [0.25] predicted was  [0.29714823]\n",
      "Error  214 is  0.13173223 correct was [0.25] predicted was  [0.38173223]\n",
      "Error  215 is  0.13042808 correct was [0.25] predicted was  [0.38042808]\n",
      "Error  216 is  0.049339503 correct was [0.32142857] predicted was  [0.37076807]\n",
      "Error  217 is  0.03161241 correct was [0.25] predicted was  [0.21838759]\n",
      "Error  218 is  0.038066924 correct was [0.35714287] predicted was  [0.3952098]\n",
      "Error  219 is  0.014634557 correct was [0.07142857] predicted was  [0.08606313]\n",
      "Error  220 is  0.01802022 correct was [0.07142857] predicted was  [0.08944879]\n",
      "Error  221 is  0.05011797 correct was [0.25] predicted was  [0.30011797]\n",
      "Error  222 is  0.087932706 correct was [0.25] predicted was  [0.3379327]\n",
      "Error  223 is  0.123303145 correct was [0.42857143] predicted was  [0.3052683]\n",
      "Error  224 is  0.07192674 correct was [0.17857143] predicted was  [0.25049818]\n",
      "Error  225 is  0.14250144 correct was [0.4642857] predicted was  [0.32178426]\n",
      "Error  226 is  0.0833641 correct was [0.2857143] predicted was  [0.3690784]\n",
      "Error  227 is  0.05093676 correct was [0.39285713] predicted was  [0.34192038]\n",
      "Error  228 is  0.09481645 correct was [0.25] predicted was  [0.34481645]\n",
      "Error  229 is  0.058923498 correct was [0.25] predicted was  [0.1910765]\n",
      "Error  230 is  0.029517561 correct was [0.2857143] predicted was  [0.25619674]\n",
      "Error  231 is  0.024981871 correct was [0.17857143] predicted was  [0.2035533]\n",
      "Error  232 is  0.07876858 correct was [0.32142857] predicted was  [0.40019715]\n",
      "Error  233 is  0.15163407 correct was [0.42857143] predicted was  [0.27693737]\n",
      "Error  234 is  0.03564155 correct was [0.21428572] predicted was  [0.24992727]\n",
      "Error  235 is  0.057452217 correct was [0.21428572] predicted was  [0.27173793]\n",
      "Error  236 is  0.03559169 correct was [0.2857143] predicted was  [0.321306]\n",
      "Error  237 is  0.04262945 correct was [0.2857143] predicted was  [0.32834375]\n",
      "Error  238 is  0.07647814 correct was [0.21428572] predicted was  [0.29076385]\n",
      "Error  239 is  0.023972124 correct was [0.14285715] predicted was  [0.11888503]\n",
      "Error  240 is  0.1399779 correct was [0.32142857] predicted was  [0.46140647]\n",
      "Error  241 is  0.04920602 correct was [0.25] predicted was  [0.29920602]\n",
      "Error  242 is  0.06177236 correct was [0.21428572] predicted was  [0.27605808]\n",
      "Error  243 is  0.030513495 correct was [0.2857143] predicted was  [0.3162278]\n",
      "Error  244 is  0.19669166 correct was [0.17857143] predicted was  [0.3752631]\n",
      "Error  245 is  0.11559534 correct was [0.25] predicted was  [0.36559534]\n",
      "Error  246 is  0.049719125 correct was [0.42857143] predicted was  [0.47829056]\n",
      "Error  247 is  0.10224165 correct was [0.21428572] predicted was  [0.31652737]\n",
      "Error  248 is  0.05893649 correct was [0.21428572] predicted was  [0.2732222]\n",
      "Error  249 is  0.077205956 correct was [0.35714287] predicted was  [0.43434882]\n",
      "Error  250 is  0.34015524 correct was [0.78571427] predicted was  [0.44555902]\n",
      "Error  251 is  0.031601995 correct was [0.2857143] predicted was  [0.3173163]\n",
      "Error  252 is  0.11378312 correct was [0.25] predicted was  [0.36378312]\n",
      "Error  253 is  0.030605316 correct was [0.25] predicted was  [0.28060532]\n",
      "Error  254 is  0.07788397 correct was [0.21428572] predicted was  [0.2921697]\n",
      "Error  255 is  0.06489965 correct was [0.2857143] predicted was  [0.35061395]\n",
      "Error  256 is  0.08964452 correct was [0.2857143] predicted was  [0.37535882]\n",
      "Error  257 is  0.18177223 correct was [0.5] predicted was  [0.31822777]\n",
      "Error  258 is  0.03831911 correct was [0.21428572] predicted was  [0.1759666]\n",
      "Error  259 is  0.10554597 correct was [0.2857143] predicted was  [0.39126027]\n",
      "Error  260 is  0.11384687 correct was [0.2857143] predicted was  [0.39956117]\n",
      "Error  261 is  0.028041705 correct was [0.17857143] predicted was  [0.15052973]\n",
      "Error  262 is  0.024155907 correct was [0.10714286] predicted was  [0.13129877]\n",
      "Error  263 is  0.16632035 correct was [0.17857143] predicted was  [0.3448918]\n",
      "Error  264 is  0.0343934 correct was [0.32142857] predicted was  [0.35582197]\n",
      "Error  265 is  0.10445091 correct was [0.32142857] predicted was  [0.42587948]\n",
      "Error  266 is  0.07127175 correct was [0.32142857] predicted was  [0.3927003]\n",
      "Error  267 is  0.052132696 correct was [0.2857143] predicted was  [0.337847]\n",
      "Error  268 is  0.05656311 correct was [0.2857143] predicted was  [0.3422774]\n",
      "Error  269 is  0.118724346 correct was [0.25] predicted was  [0.36872435]\n",
      "Error  270 is  0.15677553 correct was [0.5714286] predicted was  [0.41465306]\n",
      "Error  271 is  0.03566268 correct was [0.2857143] predicted was  [0.25005162]\n",
      "Error  272 is  0.050218105 correct was [0.25] predicted was  [0.3002181]\n",
      "Error  273 is  0.11310162 correct was [0.21428572] predicted was  [0.32738733]\n",
      "Error  274 is  0.07586488 correct was [0.32142857] predicted was  [0.39729345]\n",
      "Error  275 is  0.025085106 correct was [0.17857143] predicted was  [0.20365654]\n",
      "Error  276 is  0.07108462 correct was [0.5] predicted was  [0.42891538]\n",
      "Error  277 is  0.0558483 correct was [0.35714287] predicted was  [0.30129457]\n",
      "Error  278 is  0.21352488 correct was [0.64285713] predicted was  [0.42933226]\n",
      "Error  279 is  0.077883184 correct was [0.35714287] predicted was  [0.27925968]\n",
      "Error  280 is  0.1116004 correct was [0.25] predicted was  [0.3616004]\n",
      "Error  281 is  0.07273969 correct was [0.2857143] predicted was  [0.358454]\n",
      "Error  282 is  0.09004316 correct was [0.32142857] predicted was  [0.41147172]\n",
      "Error  283 is  0.10334584 correct was [0.32142857] predicted was  [0.4247744]\n",
      "Error  284 is  0.054548994 correct was [0.25] predicted was  [0.195451]\n",
      "Error  285 is  0.12408714 correct was [0.14285715] predicted was  [0.2669443]\n",
      "Error  286 is  0.10823484 correct was [0.35714287] predicted was  [0.24890803]\n",
      "Error  287 is  0.065350145 correct was [0.32142857] predicted was  [0.3867787]\n",
      "Error  288 is  0.073766276 correct was [0.32142857] predicted was  [0.24766229]\n",
      "Error  289 is  0.064630404 correct was [0.21428572] predicted was  [0.27891612]\n",
      "Error  290 is  0.049690664 correct was [0.39285713] predicted was  [0.4425478]\n",
      "Error  291 is  0.086291134 correct was [0.35714287] predicted was  [0.443434]\n",
      "Error  292 is  0.08149466 correct was [0.2857143] predicted was  [0.36720896]\n",
      "Error  293 is  0.04027459 correct was [0.32142857] predicted was  [0.36170316]\n",
      "Error  294 is  0.02561915 correct was [0.25] predicted was  [0.27561915]\n",
      "Error  295 is  0.02994588 correct was [0.14285715] predicted was  [0.17280303]\n",
      "Error  296 is  0.07203469 correct was [0.4642857] predicted was  [0.392251]\n",
      "Error  297 is  0.05458972 correct was [0.2857143] predicted was  [0.34030402]\n",
      "Error  298 is  0.07400295 correct was [0.2857143] predicted was  [0.35971725]\n",
      "Error  299 is  0.103102416 correct was [0.32142857] predicted was  [0.42453098]\n",
      "Error  300 is  0.1247517 correct was [0.21428572] predicted was  [0.33903742]\n",
      "Error  301 is  0.052699894 correct was [0.2857143] predicted was  [0.3384142]\n",
      "Error  302 is  0.058515668 correct was [0.53571427] predicted was  [0.59422994]\n",
      "Error  303 is  0.1398057 correct was [0.17857143] predicted was  [0.31837714]\n",
      "Error  304 is  0.03976336 correct was [0.32142857] predicted was  [0.2816652]\n",
      "Error  305 is  0.13663971 correct was [0.25] predicted was  [0.3866397]\n",
      "Error  306 is  0.13640112 correct was [0.5714286] predicted was  [0.43502748]\n",
      "Error  307 is  0.12554139 correct was [0.60714287] predicted was  [0.48160148]\n",
      "Error  308 is  0.055458397 correct was [0.2857143] predicted was  [0.3411727]\n",
      "Error  309 is  0.035913676 correct was [0.32142857] predicted was  [0.35734224]\n",
      "Error  310 is  0.053566188 correct was [0.32142857] predicted was  [0.37499475]\n",
      "Error  311 is  0.055089653 correct was [0.35714287] predicted was  [0.3020532]\n",
      "Error  312 is  0.04819736 correct was [0.32142857] predicted was  [0.36962593]\n",
      "Error  313 is  0.060043275 correct was [0.39285713] predicted was  [0.33281386]\n",
      "Error  314 is  0.061663717 correct was [0.4642857] predicted was  [0.40262198]\n",
      "Error  315 is  0.12485868 correct was [0.39285713] predicted was  [0.26799846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error  316 is  0.075119674 correct was [0.39285713] predicted was  [0.31773746]\n",
      "Error  317 is  0.04005553 correct was [0.17857143] predicted was  [0.21862696]\n",
      "Error  318 is  0.088750854 correct was [0.21428572] predicted was  [0.30303657]\n",
      "Error  319 is  0.13225254 correct was [0.2857143] predicted was  [0.41796684]\n",
      "Error  320 is  0.042846918 correct was [0.25] predicted was  [0.29284692]\n",
      "Error  321 is  0.039042026 correct was [0.32142857] predicted was  [0.28238654]\n",
      "Error  322 is  0.016617827 correct was [0.10714286] predicted was  [0.12376069]\n",
      "Error  323 is  0.12692821 correct was [0.53571427] predicted was  [0.40878606]\n",
      "Error  324 is  0.035764724 correct was [0.32142857] predicted was  [0.28566384]\n",
      "Error  325 is  0.08164233 correct was [0.35714287] predicted was  [0.4387852]\n",
      "Error  326 is  0.1088932 correct was [0.32142857] predicted was  [0.21253537]\n",
      "Error  327 is  0.3748115 correct was [0.14285715] predicted was  [-0.23195435]\n",
      "Error  328 is  0.080869466 correct was [0.17857143] predicted was  [0.2594409]\n",
      "Error  329 is  0.09919283 correct was [0.42857143] predicted was  [0.3293786]\n",
      "Error  330 is  0.04310423 correct was [0.35714287] predicted was  [0.4002471]\n",
      "Error  331 is  0.10204989 correct was [0.64285713] predicted was  [0.54080725]\n",
      "Error  332 is  0.037096024 correct was [0.25] predicted was  [0.28709602]\n",
      "Error  333 is  0.057423443 correct was [0.2857143] predicted was  [0.34313774]\n",
      "Error  334 is  0.10355061 correct was [0.64285713] predicted was  [0.5393065]\n",
      "Error  335 is  0.027306572 correct was [0.25] predicted was  [0.22269343]\n",
      "Error  336 is  0.04433793 correct was [0.39285713] predicted was  [0.43719506]\n",
      "Error  337 is  0.04148274 correct was [0.10714286] predicted was  [0.1486256]\n",
      "Error  338 is  0.037094116 correct was [0.25] predicted was  [0.28709412]\n",
      "Error  339 is  0.06468913 correct was [0.32142857] predicted was  [0.3861177]\n",
      "Error  340 is  0.077974826 correct was [0.17857143] predicted was  [0.25654626]\n",
      "Error  341 is  0.05473113 correct was [0.25] predicted was  [0.30473113]\n",
      "Error  342 is  0.10391106 correct was [0.21428572] predicted was  [0.31819677]\n",
      "Error  343 is  0.03535959 correct was [0.32142857] predicted was  [0.35678816]\n",
      "Error  344 is  0.060637146 correct was [0.14285715] predicted was  [0.2034943]\n",
      "Error  345 is  0.10307506 correct was [0.4642857] predicted was  [0.56736076]\n",
      "Error  346 is  0.04077865 correct was [0.17857143] predicted was  [0.21935008]\n",
      "Error  347 is  0.05210647 correct was [0.2857143] predicted was  [0.33782077]\n",
      "Error  348 is  0.021505713 correct was [0.21428572] predicted was  [0.19278]\n",
      "Error  349 is  0.09072341 correct was [0.21428572] predicted was  [0.30500913]\n",
      "Error  350 is  0.11782256 correct was [0.17857143] predicted was  [0.296394]\n",
      "Error  351 is  0.057712615 correct was [0.35714287] predicted was  [0.29943025]\n",
      "Error  352 is  0.10163745 correct was [0.2857143] predicted was  [0.38735175]\n",
      "Error  353 is  0.16207254 correct was [0.53571427] predicted was  [0.37364173]\n",
      "Error  354 is  0.06930646 correct was [0.2857143] predicted was  [0.35502076]\n",
      "Error  355 is  0.03989017 correct was [0.21428572] predicted was  [0.17439555]\n",
      "Error  356 is  0.03542766 correct was [0.2857143] predicted was  [0.32114196]\n",
      "Error  357 is  0.10123989 correct was [0.42857143] predicted was  [0.32733154]\n",
      "Error  358 is  0.068984196 correct was [0.2857143] predicted was  [0.2167301]\n",
      "Error  359 is  0.28040284 correct was [0.6785714] predicted was  [0.39816856]\n",
      "Error  360 is  0.03960921 correct was [0.17857143] predicted was  [0.21818064]\n",
      "Error  361 is  0.07019462 correct was [0.21428572] predicted was  [0.28448033]\n",
      "Error  362 is  0.031748295 correct was [0.21428572] predicted was  [0.24603401]\n",
      "Error  363 is  0.06686489 correct was [0.2857143] predicted was  [0.2188494]\n",
      "Error  364 is  0.14558882 correct was [0.60714287] predicted was  [0.46155405]\n",
      "Error  365 is  0.17705429 correct was [0.71428573] predicted was  [0.53723145]\n",
      "Error  366 is  0.03295955 correct was [0.2857143] predicted was  [0.31867385]\n",
      "Error  367 is  0.057342738 correct was [0.32142857] predicted was  [0.3787713]\n",
      "Error  368 is  0.07988235 correct was [0.4642857] predicted was  [0.38440335]\n",
      "Error  369 is  0.05078508 correct was [0.21428572] predicted was  [0.2650708]\n",
      "Error  370 is  0.04835309 correct was [0.21428572] predicted was  [0.2626388]\n",
      "Error  371 is  0.0689366 correct was [0.17857143] predicted was  [0.24750803]\n",
      "Error  372 is  0.32011557 correct was [0.78571427] predicted was  [0.4655987]\n",
      "Error  373 is  0.102918446 correct was [0.35714287] predicted was  [0.4600613]\n",
      "Error  374 is  0.11168784 correct was [0.35714287] predicted was  [0.4688307]\n",
      "Error  375 is  0.049200147 correct was [0.32142857] predicted was  [0.3706287]\n",
      "Error  376 is  0.12287378 correct was [0.25] predicted was  [0.37287378]\n",
      "Error  377 is  0.11624141 correct was [0.35714287] predicted was  [0.24090146]\n",
      "Error  378 is  0.060260832 correct was [0.35714287] predicted was  [0.4174037]\n",
      "Error  379 is  0.041900456 correct was [0.39285713] predicted was  [0.35095668]\n",
      "Error  380 is  0.12885937 correct was [0.4642857] predicted was  [0.33542633]\n",
      "Error  381 is  0.021796227 correct was [0.21428572] predicted was  [0.23608194]\n",
      "Error  382 is  0.11300267 correct was [0.21428572] predicted was  [0.3272884]\n",
      "Error  383 is  0.027800813 correct was [0.17857143] predicted was  [0.20637225]\n",
      "Error  384 is  0.03224793 correct was [0.2857143] predicted was  [0.25346637]\n",
      "Error  385 is  0.052551806 correct was [0.35714287] predicted was  [0.40969467]\n",
      "Error  386 is  0.03310561 correct was [0.25] predicted was  [0.2831056]\n",
      "Error  387 is  0.09049603 correct was [0.32142857] predicted was  [0.4119246]\n",
      "Error  388 is  0.11861862 correct was [0.21428572] predicted was  [0.33290434]\n",
      "Error  389 is  0.063638985 correct was [0.35714287] predicted was  [0.29350388]\n",
      "Error  390 is  0.1335833 correct was [0.5] predicted was  [0.3664167]\n",
      "Error  391 is  0.052026927 correct was [0.35714287] predicted was  [0.4091698]\n",
      "Error  392 is  0.04034853 correct was [0.25] predicted was  [0.29034853]\n",
      "Error  393 is  0.045762748 correct was [0.42857143] predicted was  [0.3828087]\n",
      "Error  394 is  0.09739861 correct was [0.2857143] predicted was  [0.3831129]\n",
      "Error  395 is  0.039664328 correct was [0.35714287] predicted was  [0.3968072]\n",
      "Error  396 is  0.029486418 correct was [0.21428572] predicted was  [0.1847993]\n",
      "Error  397 is  0.04243379 correct was [0.10714286] predicted was  [0.14957665]\n",
      "Error  398 is  0.13257775 correct was [0.2857143] predicted was  [0.41829205]\n",
      "Error  399 is  0.029008389 correct was [0.25] predicted was  [0.2790084]\n",
      "Error  400 is  0.12675244 correct was [0.35714287] predicted was  [0.4838953]\n",
      "Error  401 is  0.08039242 correct was [0.35714287] predicted was  [0.4375353]\n",
      "Error  402 is  0.02208601 correct was [0.17857143] predicted was  [0.15648542]\n",
      "Error  403 is  0.087754935 correct was [0.32142857] predicted was  [0.4091835]\n",
      "Error  404 is  0.093476266 correct was [0.42857143] predicted was  [0.33509517]\n",
      "Error  405 is  0.026481777 correct was [0.14285715] predicted was  [0.16933893]\n",
      "Error  406 is  0.08251628 correct was [0.2857143] predicted was  [0.36823058]\n",
      "Error  407 is  0.06574091 correct was [0.2857143] predicted was  [0.3514552]\n",
      "Error  408 is  0.13897939 correct was [0.35714287] predicted was  [0.21816348]\n",
      "Error  409 is  0.1029852 correct was [0.60714287] predicted was  [0.50415766]\n",
      "Error  410 is  0.042158335 correct was [0.2857143] predicted was  [0.32787263]\n",
      "Error  411 is  0.118411124 correct was [0.39285713] predicted was  [0.51126826]\n",
      "Error  412 is  0.14027405 correct was [0.5] predicted was  [0.35972595]\n",
      "Error  413 is  0.029463261 correct was [0.14285715] predicted was  [0.11339389]\n",
      "Error  414 is  0.14543182 correct was [0.64285713] predicted was  [0.49742532]\n",
      "Error  415 is  0.03277242 correct was [0.21428572] predicted was  [0.24705814]\n",
      "Error  416 is  0.12978283 correct was [0.17857143] predicted was  [0.30835426]\n",
      "Error  417 is  0.28351712 correct was [0.75] predicted was  [0.46648288]\n",
      "Error  418 is  0.044189483 correct was [0.32142857] predicted was  [0.27723908]\n",
      "Error  419 is  0.088257164 correct was [0.32142857] predicted was  [0.40968573]\n",
      "Error  420 is  0.03377995 correct was [0.32142857] predicted was  [0.35520852]\n",
      "Error  421 is  0.058691353 correct was [0.2857143] predicted was  [0.34440565]\n",
      "Error  422 is  0.06819981 correct was [0.35714287] predicted was  [0.28894305]\n",
      "Error  423 is  0.020776898 correct was [0.14285715] predicted was  [0.16363405]\n",
      "Error  424 is  0.061239004 correct was [0.25] predicted was  [0.311239]\n",
      "Error  425 is  0.05328545 correct was [0.32142857] predicted was  [0.37471402]\n",
      "Error  426 is  0.19198477 correct was [0.71428573] predicted was  [0.52230096]\n",
      "Error  427 is  0.04813692 correct was [0.2857143] predicted was  [0.33385122]\n",
      "Error  428 is  0.106547534 correct was [0.35714287] predicted was  [0.25059533]\n",
      "Error  429 is  0.095195934 correct was [0.32142857] predicted was  [0.22623263]\n",
      "Error  430 is  0.034252435 correct was [0.32142857] predicted was  [0.28717613]\n",
      "Error  431 is  0.07921347 correct was [0.2857143] predicted was  [0.36492777]\n",
      "Error  432 is  0.06348011 correct was [0.2857143] predicted was  [0.3491944]\n",
      "Error  433 is  0.079414755 correct was [0.4642857] predicted was  [0.54370046]\n",
      "Error  434 is  0.13582307 correct was [0.39285713] predicted was  [0.25703406]\n",
      "Error  435 is  0.045116276 correct was [0.32142857] predicted was  [0.36654484]\n",
      "Error  436 is  0.18791789 correct was [0.60714287] predicted was  [0.41922498]\n",
      "Error  437 is  0.12618846 correct was [0.6785714] predicted was  [0.55238295]\n",
      "Error  438 is  0.058951378 correct was [0.25] predicted was  [0.30895138]\n",
      "Error  439 is  0.075721234 correct was [0.32142857] predicted was  [0.3971498]\n",
      "Error  440 is  0.09673056 correct was [0.2857143] predicted was  [0.38244486]\n",
      "Error  441 is  0.03774242 correct was [0.2857143] predicted was  [0.24797188]\n",
      "Error  442 is  0.062024683 correct was [0.32142857] predicted was  [0.38345325]\n",
      "Error  443 is  0.04535708 correct was [0.2857143] predicted was  [0.33107138]\n",
      "Error  444 is  0.07321501 correct was [0.25] predicted was  [0.323215]\n",
      "Error  445 is  0.42863923 correct was [0.14285715] predicted was  [-0.2857821]\n",
      "Error  446 is  0.12107484 correct was [0.32142857] predicted was  [0.20035373]\n",
      "Error  447 is  0.06706938 correct was [0.2857143] predicted was  [0.35278368]\n",
      "Error  448 is  0.07593173 correct was [0.35714287] predicted was  [0.28121114]\n",
      "Error  449 is  0.08447012 correct was [0.2857143] predicted was  [0.37018442]\n",
      "Error  450 is  0.079581946 correct was [0.2857143] predicted was  [0.36529624]\n",
      "Error  451 is  0.08502266 correct was [0.2857143] predicted was  [0.37073696]\n",
      "Error  452 is  0.07862648 correct was [0.2857143] predicted was  [0.36434078]\n",
      "Error  453 is  0.12299189 correct was [0.2857143] predicted was  [0.4087062]\n",
      "Error  454 is  0.11492509 correct was [0.39285713] predicted was  [0.27793205]\n",
      "Error  455 is  0.08025676 correct was [0.35714287] predicted was  [0.43739963]\n",
      "Error  456 is  0.10354914 correct was [0.21428572] predicted was  [0.31783485]\n",
      "Error  457 is  0.098221034 correct was [0.2857143] predicted was  [0.38393533]\n",
      "Error  458 is  0.034945354 correct was [0.17857143] predicted was  [0.14362608]\n",
      "Error  459 is  0.1709426 correct was [0.5714286] predicted was  [0.400486]\n",
      "Error  460 is  0.060423046 correct was [0.14285715] predicted was  [0.2032802]\n",
      "Error  461 is  0.078967065 correct was [0.32142857] predicted was  [0.40039563]\n",
      "Error  462 is  0.08586547 correct was [0.2857143] predicted was  [0.37157977]\n",
      "Error  463 is  0.07135782 correct was [0.2857143] predicted was  [0.35707211]\n",
      "Error  464 is  0.1461477 correct was [0.32142857] predicted was  [0.46757627]\n",
      "Error  465 is  0.049785554 correct was [0.35714287] predicted was  [0.3073573]\n",
      "Error  466 is  0.053817406 correct was [0.21428572] predicted was  [0.26810312]\n",
      "Error  467 is  0.12617752 correct was [0.32142857] predicted was  [0.4476061]\n",
      "Error  468 is  0.06320009 correct was [0.2857143] predicted was  [0.34891438]\n",
      "Error  469 is  0.1450176 correct was [0.32142857] predicted was  [0.46644616]\n",
      "Error  470 is  0.23458454 correct was [0.32142857] predicted was  [0.5560131]\n",
      "Error  471 is  0.035069227 correct was [0.21428572] predicted was  [0.24935494]\n",
      "Error  472 is  0.07063413 correct was [0.25] predicted was  [0.32063413]\n",
      "Error  473 is  0.06790802 correct was [0.32142857] predicted was  [0.3893366]\n",
      "Error  474 is  0.10152364 correct was [0.25] predicted was  [0.35152364]\n",
      "Error  475 is  0.057554454 correct was [0.32142857] predicted was  [0.37898302]\n",
      "Error  476 is  0.25020164 correct was [0.60714287] predicted was  [0.35694122]\n",
      "Error  477 is  0.030672163 correct was [0.2857143] predicted was  [0.31638646]\n",
      "Error  478 is  0.06557752 correct was [0.17857143] predicted was  [0.24414895]\n",
      "Error  479 is  0.046747357 correct was [0.32142857] predicted was  [0.2746812]\n",
      "Error  480 is  0.07920255 correct was [0.21428572] predicted was  [0.29348826]\n",
      "Error  481 is  0.12370595 correct was [0.4642857] predicted was  [0.34057975]\n",
      "Error  482 is  0.061677933 correct was [0.25] predicted was  [0.31167793]\n",
      "Error  483 is  0.06898746 correct was [0.2857143] predicted was  [0.35470176]\n",
      "Error  484 is  0.15606979 correct was [0.4642857] predicted was  [0.6203555]\n",
      "Error  485 is  0.071496695 correct was [0.32142857] predicted was  [0.39292526]\n",
      "Error  486 is  0.048704118 correct was [0.32142857] predicted was  [0.37013268]\n",
      "Error  487 is  0.062812686 correct was [0.53571427] predicted was  [0.47290158]\n",
      "Error  488 is  0.11305532 correct was [0.2857143] predicted was  [0.39876962]\n",
      "Error  489 is  0.1617305 correct was [0.32142857] predicted was  [0.48315907]\n",
      "Error  490 is  0.20115077 correct was [0.21428572] predicted was  [0.01313494]\n",
      "Error  491 is  0.02613534 correct was [0.17857143] predicted was  [0.20470677]\n",
      "Error  492 is  0.027466483 correct was [0.10714286] predicted was  [0.07967637]\n",
      "Error  493 is  0.052113682 correct was [0.14285715] predicted was  [0.19497083]\n",
      "Error  494 is  0.15088126 correct was [0.32142857] predicted was  [0.47230983]\n",
      "Error  495 is  0.059160054 correct was [0.35714287] predicted was  [0.41630292]\n",
      "Error  496 is  0.05316156 correct was [0.39285713] predicted was  [0.33969557]\n",
      "Error  497 is  0.044775695 correct was [0.14285715] predicted was  [0.09808145]\n",
      "Error  498 is  0.09603199 correct was [0.2857143] predicted was  [0.3817463]\n",
      "Error  499 is  0.05017495 correct was [0.25] predicted was  [0.30017495]\n",
      "Error  500 is  0.06922831 correct was [0.21428572] predicted was  [0.28351402]\n",
      "Error  501 is  0.017461114 correct was [0.10714286] predicted was  [0.12460397]\n",
      "Error  502 is  0.051098406 correct was [0.39285713] predicted was  [0.44395554]\n",
      "Error  503 is  0.14432295 correct was [0.35714287] predicted was  [0.21281992]\n",
      "Error  504 is  0.040122956 correct was [0.32142857] predicted was  [0.36155152]\n",
      "Error  505 is  0.051294506 correct was [0.35714287] predicted was  [0.30584836]\n",
      "Error  506 is  0.12524673 correct was [0.32142857] predicted was  [0.4466753]\n",
      "Error  507 is  0.030199915 correct was [0.14285715] predicted was  [0.17305706]\n",
      "Error  508 is  0.23308188 correct was [0.64285713] predicted was  [0.40977526]\n",
      "Error  509 is  0.25122303 correct was [0.60714287] predicted was  [0.35591984]\n",
      "Error  510 is  0.039163724 correct was [0.21428572] predicted was  [0.25344944]\n",
      "Error  511 is  0.096838325 correct was [0.2857143] predicted was  [0.38255262]\n",
      "Error  512 is  0.076070234 correct was [0.32142857] predicted was  [0.24535833]\n",
      "Error  513 is  0.2035632 correct was [0.42857143] predicted was  [0.22500823]\n",
      "Error  514 is  0.04199186 correct was [0.14285715] predicted was  [0.18484901]\n",
      "Error  515 is  0.025637478 correct was [0.14285715] predicted was  [0.11721967]\n",
      "Error  516 is  0.026576295 correct was [0.17857143] predicted was  [0.20514773]\n",
      "Error  517 is  0.1524303 correct was [0.25] predicted was  [0.4024303]\n",
      "Error  518 is  0.11060262 correct was [0.5] predicted was  [0.38939738]\n",
      "Error  519 is  0.07774639 correct was [0.25] predicted was  [0.3277464]\n",
      "Error  520 is  0.08032358 correct was [0.25] predicted was  [0.33032358]\n",
      "Error  521 is  0.043490827 correct was [0.35714287] predicted was  [0.31365204]\n",
      "Error  522 is  0.047718406 correct was [0.21428572] predicted was  [0.16656731]\n",
      "Error  523 is  0.041870415 correct was [0.39285713] predicted was  [0.35098672]\n",
      "Error  524 is  0.0755098 correct was [0.21428572] predicted was  [0.28979552]\n",
      "Error  525 is  0.13416404 correct was [0.60714287] predicted was  [0.47297883]\n",
      "Error  526 is  0.0368834 correct was [0.2857143] predicted was  [0.2488309]\n",
      "Error  527 is  0.07649788 correct was [0.2857143] predicted was  [0.36221218]\n",
      "Error  528 is  0.063711375 correct was [0.2857143] predicted was  [0.34942567]\n",
      "Error  529 is  0.027719617 correct was [0.25] predicted was  [0.27771962]\n",
      "Error  530 is  0.0358631 correct was [0.35714287] predicted was  [0.39300597]\n",
      "Error  531 is  0.049432293 correct was [0.17857143] predicted was  [0.22800373]\n",
      "Error  532 is  0.053203642 correct was [0.35714287] predicted was  [0.4103465]\n",
      "Error  533 is  0.085639805 correct was [0.4642857] predicted was  [0.3786459]\n",
      "Error  534 is  0.20423207 correct was [0.2857143] predicted was  [0.48994637]\n",
      "Error  535 is  0.05291438 correct was [0.25] predicted was  [0.30291438]\n",
      "Error  536 is  0.047522917 correct was [0.21428572] predicted was  [0.26180863]\n",
      "Error  537 is  0.061038822 correct was [0.2857143] predicted was  [0.34675312]\n",
      "Error  538 is  0.046783715 correct was [0.42857143] predicted was  [0.47535515]\n",
      "Error  539 is  0.11344987 correct was [0.5714286] predicted was  [0.45797873]\n",
      "Error  540 is  0.035799563 correct was [0.35714287] predicted was  [0.39294243]\n",
      "Error  541 is  0.06212306 correct was [0.25] predicted was  [0.31212306]\n",
      "Error  542 is  0.046357557 correct was [0.2857143] predicted was  [0.23935674]\n",
      "Error  543 is  0.0761413 correct was [0.35714287] predicted was  [0.28100157]\n",
      "Error  544 is  0.038291365 correct was [0.32142857] predicted was  [0.2831372]\n",
      "Error  545 is  0.11593956 correct was [0.39285713] predicted was  [0.27691758]\n",
      "Error  546 is  0.18656111 correct was [0.5] predicted was  [0.3134389]\n",
      "Error  547 is  0.105430216 correct was [0.2857143] predicted was  [0.3911445]\n",
      "Error  548 is  0.029343516 correct was [0.2857143] predicted was  [0.25637078]\n",
      "Error  549 is  0.015924126 correct was [0.14285715] predicted was  [0.15878128]\n",
      "Error  550 is  0.055333406 correct was [0.14285715] predicted was  [0.19819055]\n",
      "Error  551 is  0.051396936 correct was [0.32142857] predicted was  [0.3728255]\n",
      "Error  552 is  0.08773254 correct was [0.17857143] predicted was  [0.09083889]\n",
      "Error  553 is  0.1453419 correct was [0.42857143] predicted was  [0.57391334]\n",
      "Error  554 is  0.08264655 correct was [0.39285713] predicted was  [0.3102106]\n",
      "Error  555 is  0.06748125 correct was [0.42857143] predicted was  [0.36109018]\n",
      "Error  556 is  0.15854642 correct was [0.2857143] predicted was  [0.44426072]\n",
      "Error  557 is  0.07625663 correct was [0.25] predicted was  [0.32625663]\n",
      "Error  558 is  0.09853583 correct was [0.10714286] predicted was  [0.20567869]\n",
      "Error  559 is  0.04450828 correct was [0.39285713] predicted was  [0.4373654]\n",
      "Error  560 is  0.066738755 correct was [0.32142857] predicted was  [0.2546898]\n",
      "Error  561 is  0.043177575 correct was [0.32142857] predicted was  [0.36460614]\n",
      "Error  562 is  0.045500755 correct was [0.25] predicted was  [0.29550076]\n",
      "Error  563 is  0.022828698 correct was [0.21428572] predicted was  [0.23711441]\n",
      "Error  564 is  0.09662148 correct was [0.2857143] predicted was  [0.38233578]\n",
      "Error  565 is  0.07277992 correct was [0.42857143] predicted was  [0.50135136]\n",
      "Error  566 is  0.064858645 correct was [0.2857143] predicted was  [0.35057294]\n",
      "Error  567 is  0.10738319 correct was [0.39285713] predicted was  [0.5002403]\n",
      "Error  568 is  0.076954365 correct was [0.25] predicted was  [0.32695436]\n",
      "Error  569 is  0.039811373 correct was [0.21428572] predicted was  [0.17447434]\n",
      "Error  570 is  0.03200522 correct was [0.14285715] predicted was  [0.17486237]\n",
      "Error  571 is  0.03796047 correct was [0.35714287] predicted was  [0.3191824]\n",
      "Error  572 is  0.110857695 correct was [0.42857143] predicted was  [0.31771374]\n",
      "Error  573 is  0.09091365 correct was [0.25] predicted was  [0.34091365]\n",
      "Error  574 is  0.056149498 correct was [0.17857143] predicted was  [0.23472093]\n",
      "Error  575 is  0.075023174 correct was [0.25] predicted was  [0.32502317]\n",
      "Error  576 is  0.06616613 correct was [0.32142857] predicted was  [0.3875947]\n",
      "Error  577 is  0.18361014 correct was [0.60714287] predicted was  [0.42353272]\n",
      "Error  578 is  0.036286682 correct was [0.32142857] predicted was  [0.35771525]\n",
      "Error  579 is  0.038638145 correct was [0.14285715] predicted was  [0.1814953]\n",
      "Error  580 is  0.061366796 correct was [0.25] predicted was  [0.3113668]\n",
      "Error  581 is  0.0816344 correct was [0.53571427] predicted was  [0.45407987]\n",
      "Error  582 is  0.06250745 correct was [0.39285713] predicted was  [0.33034968]\n",
      "Error  583 is  0.07467875 correct was [0.2857143] predicted was  [0.36039305]\n",
      "Error  584 is  0.10910645 correct was [0.4642857] predicted was  [0.57339215]\n",
      "Error  585 is  0.088542074 correct was [0.32142857] predicted was  [0.40997064]\n",
      "Error  586 is  0.12865299 correct was [0.35714287] predicted was  [0.48579586]\n",
      "Error  587 is  0.1758393 correct was [0.53571427] predicted was  [0.35987496]\n",
      "Error  588 is  0.03260994 correct was [0.25] predicted was  [0.28260994]\n",
      "Error  589 is  0.045966998 correct was [0.21428572] predicted was  [0.2602527]\n",
      "Error  590 is  0.02662982 correct was [0.17857143] predicted was  [0.20520125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error  591 is  0.026041284 correct was [0.17857143] predicted was  [0.20461272]\n",
      "Error  592 is  0.13271722 correct was [0.42857143] predicted was  [0.2958542]\n",
      "Error  593 is  0.08685738 correct was [0.35714287] predicted was  [0.44400024]\n",
      "Error  594 is  0.1177831 correct was [0.42857143] predicted was  [0.54635453]\n",
      "Error  595 is  0.109188884 correct was [0.2857143] predicted was  [0.39490318]\n",
      "Error  596 is  0.069538385 correct was [0.32142857] predicted was  [0.25189018]\n",
      "Error  597 is  0.106757015 correct was [0.2857143] predicted was  [0.3924713]\n",
      "Error  598 is  0.03254631 correct was [0.2857143] predicted was  [0.253168]\n",
      "Error  599 is  0.025549293 correct was [0.21428572] predicted was  [0.23983501]\n",
      "Error  600 is  0.09672052 correct was [0.5714286] predicted was  [0.47470808]\n",
      "Error  601 is  0.07476187 correct was [0.5] predicted was  [0.42523813]\n",
      "Error  602 is  0.07748645 correct was [0.10714286] predicted was  [0.1846293]\n",
      "Error  603 is  0.115926504 correct was [0.25] predicted was  [0.3659265]\n",
      "Error  604 is  0.055455267 correct was [0.35714287] predicted was  [0.41259813]\n",
      "Error  605 is  0.028676987 correct was [0.25] predicted was  [0.278677]\n",
      "Error  606 is  0.15120581 correct was [0.42857143] predicted was  [0.57977724]\n",
      "Error  607 is  0.046711102 correct was [0.21428572] predicted was  [0.26099682]\n",
      "Error  608 is  0.0240978 correct was [0.21428572] predicted was  [0.19018792]\n",
      "Error  609 is  0.043177426 correct was [0.35714287] predicted was  [0.4003203]\n",
      "Error  610 is  0.16065001 correct was [0.25] predicted was  [0.41065]\n",
      "Error  611 is  0.094468564 correct was [0.42857143] predicted was  [0.33410287]\n",
      "Error  612 is  0.035484463 correct was [0.32142857] predicted was  [0.2859441]\n",
      "Error  613 is  0.030293077 correct was [0.2857143] predicted was  [0.31600738]\n",
      "Error  614 is  0.032716528 correct was [0.17857143] predicted was  [0.21128796]\n",
      "Error  615 is  0.05280122 correct was [0.2857143] predicted was  [0.33851552]\n",
      "Error  616 is  0.0458076 correct was [0.25] predicted was  [0.2958076]\n",
      "Error  617 is  0.029420257 correct was [0.21428572] predicted was  [0.18486546]\n",
      "Error  618 is  0.047135085 correct was [0.4642857] predicted was  [0.41715062]\n",
      "Error  619 is  0.04097268 correct was [0.32142857] predicted was  [0.36240125]\n",
      "Error  620 is  0.033823997 correct was [0.2857143] predicted was  [0.2518903]\n",
      "Error  621 is  0.0294739 correct was [0.21428572] predicted was  [0.24375962]\n",
      "Error  622 is  0.054923385 correct was [0.2857143] predicted was  [0.34063768]\n",
      "Error  623 is  0.06224081 correct was [0.4642857] predicted was  [0.4020449]\n",
      "Error  624 is  0.06532028 correct was [0.32142857] predicted was  [0.25610828]\n",
      "Error  625 is  0.08237252 correct was [0.2857143] predicted was  [0.3680868]\n",
      "Error  626 is  0.03623645 correct was [0.2857143] predicted was  [0.24947785]\n",
      "Error  627 is  0.056923002 correct was [0.2857143] predicted was  [0.3426373]\n",
      "Error  628 is  0.07642433 correct was [0.32142857] predicted was  [0.3978529]\n",
      "Error  629 is  0.04677868 correct was [0.21428572] predicted was  [0.16750704]\n",
      "Error  630 is  0.054545224 correct was [0.35714287] predicted was  [0.4116881]\n",
      "Error  631 is  0.0257819 correct was [0.14285715] predicted was  [0.16863905]\n",
      "Error  632 is  0.03784725 correct was [0.32142857] predicted was  [0.35927582]\n",
      "Error  633 is  0.052084684 correct was [0.21428572] predicted was  [0.16220103]\n",
      "Error  634 is  0.11708 correct was [0.42857143] predicted was  [0.54565144]\n",
      "Error  635 is  0.104082584 correct was [0.25] predicted was  [0.35408258]\n",
      "Error  636 is  0.2003324 correct was [0.25] predicted was  [0.4503324]\n",
      "Error  637 is  0.035059184 correct was [0.32142857] predicted was  [0.35648775]\n",
      "Error  638 is  0.19100302 correct was [0.60714287] predicted was  [0.41613984]\n",
      "Error  639 is  0.10428703 correct was [0.53571427] predicted was  [0.6400013]\n",
      "Error  640 is  0.06627843 correct was [0.4642857] predicted was  [0.39800727]\n",
      "Error  641 is  0.026070118 correct was [0.25] predicted was  [0.27607012]\n",
      "Error  642 is  0.050072327 correct was [0.21428572] predicted was  [0.26435804]\n",
      "Error  643 is  0.04267779 correct was [0.14285715] predicted was  [0.18553494]\n",
      "Error  644 is  0.07045056 correct was [0.25] predicted was  [0.17954944]\n",
      "Error  645 is  0.03922406 correct was [0.14285715] predicted was  [0.18208121]\n",
      "Error  646 is  0.06964105 correct was [0.39285713] predicted was  [0.4624982]\n",
      "Error  647 is  0.0421585 correct was [0.21428572] predicted was  [0.25644422]\n",
      "Error  648 is  0.037606806 correct was [0.2857143] predicted was  [0.3233211]\n",
      "Error  649 is  0.056599826 correct was [0.32142857] predicted was  [0.3780284]\n",
      "Error  650 is  0.027977467 correct was [0.25] predicted was  [0.27797747]\n",
      "Error  651 is  0.06018257 correct was [0.25] predicted was  [0.31018257]\n",
      "Error  652 is  0.06513715 correct was [0.25] predicted was  [0.31513715]\n",
      "Error  653 is  0.036333725 correct was [0.2857143] predicted was  [0.24938057]\n",
      "Error  654 is  0.033836514 correct was [0.2857143] predicted was  [0.25187778]\n",
      "Error  655 is  0.07320365 correct was [0.32142857] predicted was  [0.39463222]\n",
      "Error  656 is  0.04438235 correct was [0.21428572] predicted was  [0.25866807]\n",
      "Error  657 is  0.087127715 correct was [0.17857143] predicted was  [0.26569915]\n",
      "Error  658 is  0.036539212 correct was [0.17857143] predicted was  [0.21511064]\n",
      "Error  659 is  0.091012895 correct was [0.39285713] predicted was  [0.30184424]\n",
      "Error  660 is  0.1518172 correct was [0.25] predicted was  [0.4018172]\n",
      "Error  661 is  0.11456236 correct was [0.2857143] predicted was  [0.40027666]\n",
      "Error  662 is  0.053995937 correct was [0.32142857] predicted was  [0.3754245]\n",
      "Error  663 is  0.20047665 correct was [0.5] predicted was  [0.29952335]\n",
      "Error  664 is  0.42066363 correct was [0.17857143] predicted was  [0.59923506]\n",
      "Error  665 is  0.039799705 correct was [0.25] predicted was  [0.2102003]\n",
      "Error  666 is  0.07577339 correct was [0.17857143] predicted was  [0.25434482]\n",
      "Error  667 is  0.06257622 correct was [0.2857143] predicted was  [0.22313808]\n",
      "Error  668 is  0.113025695 correct was [0.17857143] predicted was  [0.29159713]\n",
      "Error  669 is  0.06446433 correct was [0.25] predicted was  [0.31446433]\n",
      "Error  670 is  0.10691512 correct was [0.25] predicted was  [0.35691512]\n",
      "Error  671 is  0.042601347 correct was [0.25] predicted was  [0.29260135]\n",
      "Error  672 is  0.03724374 correct was [0.21428572] predicted was  [0.25152946]\n",
      "Error  673 is  0.05767837 correct was [0.4642857] predicted was  [0.5219641]\n",
      "Error  674 is  0.19474992 correct was [0.32142857] predicted was  [0.5161785]\n",
      "Error  675 is  0.061718166 correct was [0.35714287] predicted was  [0.2954247]\n",
      "Error  676 is  0.18752831 correct was [0.6785714] predicted was  [0.4910431]\n",
      "Error  677 is  0.026094317 correct was [0.21428572] predicted was  [0.24038003]\n",
      "Error  678 is  0.054296017 correct was [0.25] predicted was  [0.30429602]\n",
      "Error  679 is  0.051568598 correct was [0.2857143] predicted was  [0.3372829]\n",
      "Error  680 is  0.06848201 correct was [0.2857143] predicted was  [0.3541963]\n",
      "Error  681 is  0.07696256 correct was [0.2857143] predicted was  [0.36267686]\n",
      "Error  682 is  0.09183046 correct was [0.32142857] predicted was  [0.41325903]\n",
      "Error  683 is  0.051018476 correct was [0.25] predicted was  [0.30101848]\n",
      "Error  684 is  0.06820676 correct was [0.42857143] predicted was  [0.36036468]\n",
      "Error  685 is  0.047496215 correct was [0.17857143] predicted was  [0.22606765]\n",
      "Error  686 is  0.12728585 correct was [0.21428572] predicted was  [0.34157157]\n",
      "Error  687 is  0.07679221 correct was [0.42857143] predicted was  [0.35177922]\n",
      "Error  688 is  0.057488203 correct was [0.25] predicted was  [0.3074882]\n",
      "Error  689 is  0.119555175 correct was [0.39285713] predicted was  [0.27330196]\n",
      "Error  690 is  0.10165566 correct was [0.39285713] predicted was  [0.4945128]\n",
      "Error  691 is  0.10118273 correct was [0.17857143] predicted was  [0.27975416]\n",
      "Error  692 is  0.04696943 correct was [0.17857143] predicted was  [0.22554086]\n",
      "Error  693 is  0.2283945 correct was [0.42857143] predicted was  [0.20017694]\n",
      "Error  694 is  0.061902538 correct was [0.17857143] predicted was  [0.24047397]\n",
      "Error  695 is  0.098841324 correct was [0.21428572] predicted was  [0.31312704]\n",
      "Error  696 is  0.021710753 correct was [0.21428572] predicted was  [0.23599647]\n",
      "Error  697 is  0.056307226 correct was [0.14285715] predicted was  [0.19916438]\n",
      "Error  698 is  0.11781615 correct was [0.39285713] predicted was  [0.5106733]\n",
      "Error  699 is  0.04290214 correct was [0.32142857] predicted was  [0.27852643]\n",
      "Error  700 is  0.027906299 correct was [0.21428572] predicted was  [0.24219202]\n",
      "Error  701 is  0.054984212 correct was [0.25] predicted was  [0.3049842]\n",
      "Error  702 is  0.04688412 correct was [0.35714287] predicted was  [0.404027]\n",
      "Error  703 is  0.09329793 correct was [0.32142857] predicted was  [0.4147265]\n",
      "Error  704 is  0.059717536 correct was [0.25] predicted was  [0.30971754]\n",
      "Error  705 is  0.07855961 correct was [0.42857143] predicted was  [0.35001183]\n",
      "Error  706 is  0.050424628 correct was [0.10714286] predicted was  [0.15756749]\n",
      "Error  707 is  0.15058789 correct was [0.32142857] predicted was  [0.47201645]\n",
      "Error  708 is  0.076919794 correct was [0.25] predicted was  [0.3269198]\n",
      "Error  709 is  0.03983721 correct was [0.2857143] predicted was  [0.3255515]\n",
      "Error  710 is  0.10561392 correct was [0.32142857] predicted was  [0.42704248]\n",
      "Error  711 is  0.11750245 correct was [0.5] predicted was  [0.38249755]\n",
      "Error  712 is  0.08208686 correct was [0.39285713] predicted was  [0.31077027]\n",
      "Error  713 is  0.03306541 correct was [0.2857143] predicted was  [0.3187797]\n",
      "Error  714 is  0.12783405 correct was [0.32142857] predicted was  [0.44926262]\n",
      "Error  715 is  0.086272836 correct was [0.25] predicted was  [0.33627284]\n",
      "Error  716 is  0.103333175 correct was [0.35714287] predicted was  [0.2538097]\n",
      "Error  717 is  0.08679673 correct was [0.32142857] predicted was  [0.4082253]\n",
      "Error  718 is  0.0805144 correct was [0.2857143] predicted was  [0.3662287]\n",
      "Error  719 is  0.05150351 correct was [0.2857143] predicted was  [0.3372178]\n",
      "Error  720 is  0.0745894 correct was [0.17857143] predicted was  [0.25316083]\n",
      "Error  721 is  0.12284863 correct was [0.53571427] predicted was  [0.41286564]\n",
      "Error  722 is  0.036143273 correct was [0.2857143] predicted was  [0.32185757]\n",
      "Error  723 is  0.04726197 correct was [0.17857143] predicted was  [0.2258334]\n",
      "Error  724 is  0.04462792 correct was [0.17857143] predicted was  [0.22319935]\n",
      "Error  725 is  0.077337384 correct was [0.53571427] predicted was  [0.45837688]\n",
      "Error  726 is  0.072324276 correct was [0.5] predicted was  [0.42767572]\n",
      "Error  727 is  0.28697836 correct was [0.78571427] predicted was  [0.4987359]\n",
      "Error  728 is  0.12232131 correct was [0.5714286] predicted was  [0.4491073]\n",
      "Error  729 is  0.07384583 correct was [0.32142857] predicted was  [0.3952744]\n",
      "Error  730 is  0.10429847 correct was [0.53571427] predicted was  [0.4314158]\n",
      "Error  731 is  0.22590321 correct was [0.5714286] predicted was  [0.34552538]\n",
      "Error  732 is  0.057916045 correct was [0.25] predicted was  [0.30791605]\n",
      "Error  733 is  0.0389352 correct was [0.21428572] predicted was  [0.25322092]\n",
      "Error  734 is  0.06923768 correct was [0.2857143] predicted was  [0.35495198]\n",
      "Error  735 is  0.047509283 correct was [0.2857143] predicted was  [0.33322358]\n",
      "Error  736 is  0.193185 correct was [0.17857143] predicted was  [0.37175643]\n",
      "Error  737 is  0.09150757 correct was [0.21428572] predicted was  [0.3057933]\n",
      "Error  738 is  0.059029594 correct was [0.17857143] predicted was  [0.23760103]\n",
      "Error  739 is  0.038920403 correct was [0.25] predicted was  [0.2889204]\n",
      "Error  740 is  0.08432174 correct was [0.25] predicted was  [0.33432174]\n",
      "Error  741 is  0.1316745 correct was [0.32142857] predicted was  [0.45310307]\n",
      "Error  742 is  0.25451696 correct was [0.53571427] predicted was  [0.2811973]\n",
      "Error  743 is  0.061631292 correct was [0.42857143] predicted was  [0.36694014]\n",
      "Error  744 is  0.059322476 correct was [0.25] predicted was  [0.30932248]\n",
      "Error  745 is  0.07745823 correct was [0.2857143] predicted was  [0.36317253]\n",
      "Error  746 is  0.07513937 correct was [0.2857143] predicted was  [0.36085367]\n",
      "Error  747 is  0.031234503 correct was [0.25] predicted was  [0.2812345]\n",
      "Error  748 is  0.06713867 correct was [0.25] predicted was  [0.31713867]\n",
      "Error  749 is  0.07736963 correct was [0.35714287] predicted was  [0.27977324]\n",
      "Error  750 is  0.10091986 correct was [0.21428572] predicted was  [0.31520557]\n",
      "Error  751 is  0.056014985 correct was [0.2857143] predicted was  [0.34172928]\n",
      "Error  752 is  0.03313315 correct was [0.21428572] predicted was  [0.24741887]\n",
      "Error  753 is  0.027333856 correct was [0.21428572] predicted was  [0.18695186]\n",
      "Error  754 is  0.06786415 correct was [0.42857143] predicted was  [0.36070728]\n",
      "Error  755 is  0.029301576 correct was [0.10714286] predicted was  [0.13644443]\n",
      "Error  756 is  0.038381815 correct was [0.25] predicted was  [0.28838181]\n",
      "Error  757 is  0.1909582 correct was [0.6785714] predicted was  [0.4876132]\n",
      "Error  758 is  0.033708423 correct was [0.2857143] predicted was  [0.31942272]\n",
      "Error  759 is  0.18459985 correct was [0.2857143] predicted was  [0.47031415]\n",
      "Error  760 is  0.06462678 correct was [0.2857143] predicted was  [0.35034108]\n",
      "Error  761 is  0.09537117 correct was [0.2857143] predicted was  [0.19034313]\n",
      "Error  762 is  0.061990187 correct was [0.2857143] predicted was  [0.22372411]\n",
      "Error  763 is  0.04146275 correct was [0.2857143] predicted was  [0.32717705]\n",
      "Error  764 is  0.08587596 correct was [0.32142857] predicted was  [0.40730453]\n",
      "Error  765 is  0.041501105 correct was [0.39285713] predicted was  [0.35135603]\n",
      "Error  766 is  0.13816786 correct was [0.25] predicted was  [0.38816786]\n",
      "Error  767 is  0.13819718 correct was [0.53571427] predicted was  [0.39751709]\n",
      "Error  768 is  0.026565194 correct was [0.21428572] predicted was  [0.24085091]\n",
      "Error  769 is  0.1810239 correct was [0.64285713] predicted was  [0.46183324]\n",
      "Error  770 is  0.10896316 correct was [0.17857143] predicted was  [0.2875346]\n",
      "Error  771 is  0.041713715 correct was [0.25] predicted was  [0.2917137]\n",
      "Error  772 is  0.093370885 correct was [0.32142857] predicted was  [0.41479945]\n",
      "Error  773 is  0.16171134 correct was [0.5] predicted was  [0.33828866]\n",
      "Error  774 is  0.041011706 correct was [0.21428572] predicted was  [0.25529742]\n",
      "Error  775 is  0.06452477 correct was [0.25] predicted was  [0.31452477]\n",
      "Error  776 is  0.02275969 correct was [0.17857143] predicted was  [0.20133112]\n",
      "Error  777 is  0.09467082 correct was [0.32142857] predicted was  [0.22675775]\n",
      "Error  778 is  0.09354505 correct was [0.2857143] predicted was  [0.37925935]\n",
      "Error  779 is  0.034101263 correct was [0.17857143] predicted was  [0.2126727]\n",
      "Error  780 is  0.040104926 correct was [0.35714287] predicted was  [0.3972478]\n",
      "Error  781 is  0.04908514 correct was [0.25] predicted was  [0.29908514]\n",
      "Error  782 is  0.03716731 correct was [0.25] predicted was  [0.2871673]\n",
      "Error  783 is  0.13136205 correct was [0.4642857] predicted was  [0.33292365]\n",
      "Error  784 is  0.034671456 correct was [0.2857143] predicted was  [0.25104284]\n",
      "Error  785 is  0.053209335 correct was [0.14285715] predicted was  [0.19606648]\n",
      "Error  786 is  0.13497986 correct was [0.21428572] predicted was  [0.34926558]\n",
      "Error  787 is  0.099850655 correct was [0.25] predicted was  [0.34985065]\n",
      "Error  788 is  0.09691587 correct was [0.14285715] predicted was  [0.23977302]\n",
      "Error  789 is  0.0448066 correct was [0.25] predicted was  [0.2948066]\n",
      "Error  790 is  0.039234087 correct was [0.2857143] predicted was  [0.24648021]\n",
      "Error  791 is  0.02841556 correct was [0.21428572] predicted was  [0.24270128]\n",
      "Error  792 is  0.07526505 correct was [0.21428572] predicted was  [0.13902067]\n",
      "Error  793 is  0.10384199 correct was [0.42857143] predicted was  [0.32472944]\n",
      "Error  794 is  0.05153066 correct was [0.39285713] predicted was  [0.34132648]\n",
      "Error  795 is  0.033976555 correct was [0.25] predicted was  [0.28397655]\n",
      "Error  796 is  0.12660748 correct was [0.5714286] predicted was  [0.44482112]\n",
      "Error  797 is  0.027238183 correct was [0.10714286] predicted was  [0.13438104]\n",
      "Error  798 is  0.06867835 correct was [0.32142857] predicted was  [0.39010692]\n",
      "Error  799 is  0.07923564 correct was [0.4642857] predicted was  [0.38505006]\n",
      "Error  800 is  0.055932656 correct was [0.17857143] predicted was  [0.23450409]\n",
      "Error  801 is  0.05817485 correct was [0.25] predicted was  [0.30817485]\n",
      "Error  802 is  0.09964326 correct was [0.14285715] predicted was  [0.24250041]\n",
      "Error  803 is  0.17156404 correct was [0.6785714] predicted was  [0.50700736]\n",
      "Error  804 is  0.14041412 correct was [0.25] predicted was  [0.39041412]\n",
      "Error  805 is  0.2010181 correct was [0.5] predicted was  [0.2989819]\n",
      "Error  806 is  0.07990529 correct was [0.25] predicted was  [0.17009471]\n",
      "Error  807 is  0.06618357 correct was [0.25] predicted was  [0.31618357]\n",
      "Error  808 is  0.042565674 correct was [0.2857143] predicted was  [0.32827997]\n",
      "Error  809 is  0.02921331 correct was [0.21428572] predicted was  [0.24349903]\n",
      "Error  810 is  0.060373276 correct was [0.32142857] predicted was  [0.38180184]\n",
      "Error  811 is  0.023654953 correct was [0.17857143] predicted was  [0.20222639]\n",
      "Error  812 is  0.06893489 correct was [0.32142857] predicted was  [0.39036345]\n",
      "Error  813 is  0.017862454 correct was [0.17857143] predicted was  [0.19643389]\n",
      "Error  814 is  0.046245307 correct was [0.32142857] predicted was  [0.36767387]\n",
      "Error  815 is  0.16424026 correct was [0.21428572] predicted was  [0.37852597]\n",
      "Error  816 is  0.04221925 correct was [0.2857143] predicted was  [0.32793355]\n",
      "Error  817 is  0.0576275 correct was [0.35714287] predicted was  [0.41477036]\n",
      "Error  818 is  0.101674646 correct was [0.4642857] predicted was  [0.36261106]\n",
      "Error  819 is  0.077996075 correct was [0.35714287] predicted was  [0.43513894]\n",
      "Error  820 is  0.082460046 correct was [0.5] predicted was  [0.41753995]\n",
      "Error  821 is  0.06685445 correct was [0.32142857] predicted was  [0.388283]\n",
      "Error  822 is  0.05437082 correct was [0.35714287] predicted was  [0.4115137]\n",
      "Error  823 is  0.07368487 correct was [0.35714287] predicted was  [0.43082774]\n",
      "Error  824 is  0.07775712 correct was [0.25] predicted was  [0.32775712]\n",
      "Error  825 is  0.19805342 correct was [0.5714286] predicted was  [0.37337518]\n",
      "Error  826 is  0.036586255 correct was [0.32142857] predicted was  [0.35801482]\n",
      "Error  827 is  0.032839984 correct was [0.32142857] predicted was  [0.35426855]\n",
      "Error  828 is  0.058883667 correct was [0.25] predicted was  [0.30888367]\n",
      "Error  829 is  0.1680057 correct was [0.25] predicted was  [0.4180057]\n",
      "Error  830 is  0.07644965 correct was [0.21428572] predicted was  [0.29073536]\n",
      "Error  831 is  0.051116914 correct was [0.2857143] predicted was  [0.3368312]\n",
      "Error  832 is  0.13063201 correct was [0.32142857] predicted was  [0.45206058]\n",
      "Error  833 is  0.094656914 correct was [0.32142857] predicted was  [0.41608548]\n",
      "Error  834 is  0.12856556 correct was [0.21428572] predicted was  [0.34285128]\n",
      "Error  835 is  0.045751743 correct was [0.10714286] predicted was  [0.1528946]\n",
      "Error  836 is  0.034519404 correct was [0.2857143] predicted was  [0.3202337]\n",
      "Error  837 is  0.11500296 correct was [0.2857143] predicted was  [0.40071726]\n",
      "Error  838 is  0.118056595 correct was [0.35714287] predicted was  [0.47519946]\n",
      "Error  839 is  0.04462935 correct was [0.17857143] predicted was  [0.22320078]\n",
      "Error  840 is  0.10159737 correct was [0.39285713] predicted was  [0.29125977]\n",
      "Error  841 is  0.049573943 correct was [0.2857143] predicted was  [0.23614036]\n",
      "Error  842 is  0.09206784 correct was [0.5] predicted was  [0.40793216]\n",
      "Error  843 is  0.037117988 correct was [0.14285715] predicted was  [0.17997514]\n",
      "Error  844 is  0.056837052 correct was [0.2857143] predicted was  [0.34255135]\n",
      "Error  845 is  0.2669881 correct was [0.64285713] predicted was  [0.37586904]\n",
      "Error  846 is  0.03688526 correct was [0.25] predicted was  [0.28688526]\n",
      "Error  847 is  0.040867656 correct was [0.2857143] predicted was  [0.32658195]\n",
      "Error  848 is  0.046912566 correct was [0.21428572] predicted was  [0.26119828]\n",
      "Error  849 is  0.034098625 correct was [0.21428572] predicted was  [0.24838434]\n",
      "Error  850 is  0.095020264 correct was [0.32142857] predicted was  [0.41644883]\n",
      "Error  851 is  0.023360372 correct was [0.21428572] predicted was  [0.23764609]\n",
      "Error  852 is  0.10175353 correct was [0.5714286] predicted was  [0.46967506]\n",
      "Error  853 is  0.071628064 correct was [0.2857143] predicted was  [0.35734236]\n",
      "Error  854 is  0.07477769 correct was [0.2857143] predicted was  [0.360492]\n",
      "Error  855 is  0.07134661 correct was [0.2857143] predicted was  [0.3570609]\n",
      "Error  856 is  0.093941584 correct was [0.21428572] predicted was  [0.3082273]\n",
      "Error  857 is  0.052116275 correct was [0.25] predicted was  [0.30211627]\n",
      "Error  858 is  0.049868047 correct was [0.35714287] predicted was  [0.30727482]\n",
      "Error  859 is  0.04804465 correct was [0.42857143] predicted was  [0.38052678]\n",
      "Error  860 is  0.058083802 correct was [0.14285715] predicted was  [0.20094095]\n",
      "Error  861 is  0.093497664 correct was [0.17857143] predicted was  [0.2720691]\n",
      "Error  862 is  0.14034542 correct was [0.32142857] predicted was  [0.461774]\n",
      "Error  863 is  0.10687131 correct was [0.39285713] predicted was  [0.49972844]\n",
      "Error  864 is  0.03973104 correct was [0.25] predicted was  [0.21026896]\n",
      "Error  865 is  0.19592449 correct was [0.2857143] predicted was  [0.4816388]\n",
      "Error  866 is  0.07734445 correct was [0.42857143] predicted was  [0.5059159]\n",
      "Error  867 is  0.14551629 correct was [0.21428572] predicted was  [0.359802]\n",
      "Error  868 is  0.08132355 correct was [0.32142857] predicted was  [0.24010502]\n",
      "Error  869 is  0.23359573 correct was [0.78571427] predicted was  [0.55211854]\n",
      "Error  870 is  0.039441466 correct was [0.21428572] predicted was  [0.17484425]\n",
      "Error  871 is  0.09642699 correct was [0.17857143] predicted was  [0.27499843]\n",
      "Error  872 is  0.079995066 correct was [0.14285715] predicted was  [0.22285222]\n",
      "avg loss was 0.056586156987556084  avg val is 0.31477259690559284\n",
      "Minimum val is [0.07142857]\n",
      "RMSE:  0.07766202714665758\n",
      "Test set length:  1379  % of prdeictions within 10%:  36.76577229876722\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Scaled output test\n",
    "plt.subplot(2,1,1)\n",
    "\n",
    "# plt.plot(y_pred.detach().numpy(),'g.')# , y_train,'r.')\n",
    "plt.plot(y_pred,'g.')# , y_train,'r.')\n",
    "\n",
    "plt.ylabel('prop value')\n",
    "plt.show()\n",
    "\n",
    "# loss = torch.empty(len(y_test)) \n",
    "loss = torch.empty(len(y_test)).numpy() \n",
    "\n",
    "c=0;\n",
    "for i in range(len(y_test)):\n",
    "#     loss[i] = torch.abs(y_test[i]-y_pred.detach().float().numpy()[i])\n",
    "    loss[i] = abs(y_test[i]-y_pred[i])\n",
    "    if loss[i] > (y_test[i]*0.1):\n",
    "        c=c+1\n",
    "        print(\"Error \", c ,\"is \", loss[i], \"correct was\",y_test[i],\"predicted was \",y_pred[i])\n",
    "\n",
    "rmse = np.sqrt((((np.square(loss)).sum())/len(loss)))\n",
    "        \n",
    "        \n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(loss,'bo')\n",
    "print(\"avg loss was\", loss.sum()/len(loss),\" avg val is\",y_test.sum()/len(y_test))\n",
    "print(\"Minimum val is\",min(y_test))\n",
    "print(\"RMSE: \",rmse)\n",
    "print(\"Test set length: \",len(y_test),\" % of prdeictions within 10%: \",100-c/len(y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Mean:  0.0060313903\n",
      "MSE STD Dev:  0.0134351505\n"
     ]
    }
   ],
   "source": [
    "MSE = (np.square(loss))\n",
    "print(\"MSE Mean: \",np.mean(MSE))\n",
    "print(\"MSE STD Dev: \",np.std(MSE))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
